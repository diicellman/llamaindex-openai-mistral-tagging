{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Tagging using Mistral 7B via Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel\n",
    "from llama_index.program import LLMTextCompletionProgram\n",
    "from llama_index.llms import Ollama\n",
    "from llama_index.prompts import PromptTemplate\n",
    "from llama_index.output_parsers import PydanticOutputParser"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define output schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tag(BaseModel):\n",
    "    \"\"\"Data model for tagging.\"\"\"\n",
    "\n",
    "    text: str\n",
    "    language: str\n",
    "    sentiment: str\n",
    "    toxicity: float\n",
    "    hate: float\n",
    "    hate_threatening: float\n",
    "    violence: float"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Initialize the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_ollama_llm = llm = Ollama(model=\"mistral:latest\", base_url=\"http://localhost:11434\", temperature=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define ollama pydantic program"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_prompt_template = \"\"\"\n",
    "<s> [INST] I request you to divide the user comment below into aspects and perform sentiment analysis and give the result in sentiment analysis json format. Just return result in json format. Don't add any other comments.\n",
    "\n",
    "Note: The toxicity, hate, hate_threatening and violence scores should be in the range (0.1 - 1). The scores should be a float.\n",
    "The sentiment label should be either ['positive', 'negative', 'neutral'].\n",
    "The text label should be the comment itself. \n",
    "The language label should be a full name of the language in which the comment is written. [/INST] </s> \n",
    "[INST] comment: {user_comment} \n",
    "Answer: [/INST]\n",
    "\"\"\"\n",
    "mistral_prompt_tmpl = PromptTemplate(mistral_prompt_template)\n",
    "\n",
    "mistral_program = LLMTextCompletionProgram(\n",
    "    output_parser=PydanticOutputParser(Tag),\n",
    "    prompt=mistral_prompt_tmpl,\n",
    "    llm=mistral_ollama_llm,\n",
    "    verbose=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the tagging program to get get structured output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_output = mistral_program(user_comment=\"I love this world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': 'I love this world!',\n",
       " 'language': 'English',\n",
       " 'sentiment': 'positive',\n",
       " 'toxicity': 0.0,\n",
       " 'hate': 0.0,\n",
       " 'hate_threatening': 0.0,\n",
       " 'violence': 0.0}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_output.model_dump()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "mistral_output = mistral_program(user_comment=\"Je n'aime pas ce film, c'est le pire film jamais réalisé !\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'text': \"Je n'aime pas ce film, c'est le pire film jamais réalisé !\",\n",
       " 'language': 'French',\n",
       " 'sentiment': 'negative',\n",
       " 'toxicity': 0.3,\n",
       " 'hate': 0.6,\n",
       " 'hate_threatening': 0.1,\n",
       " 'violence': 0.1}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mistral_output.model_dump()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llamaindex-tagging",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
